research_news_task:
  description: >
    You are given a research request:
    User request: {user_request}
    Query: {query}
    Tickers: {tickers}
    Sites (optional): {sites}
    Lookback days: {days}
    Max articles: {max_articles}
    Search query: {search_query}

    Use SerperDevTool or SerpApiGoogleSearchTool to discover relevant articles
    with search_query. If tickers are provided, include them in the search terms.
    If sites are provided, use site: filters (for example: site:reuters.com OR
    site:bloomberg.com). The search is not limited to 3 sources; gather up to
    Max articles.

    For each article you choose, use ScrapeWebsiteTool to read the full content.
    If the search results include a source_url, prefer that; otherwise use the link.

    Extract for each article:
    - headline or title (if present)
    - published timestamp (ISO 8601 if present; otherwise use "unknown")
    - 1 to 3 key points grounded in the article

    Cluster the articles into 2 to 4 drivers (earnings, macro, regulation, product
    news, etc.). For each driver, explain "why it matters" using only evidence from
    the scraped sources.

    Rules:
    - Do not invent facts, dates, or citations.
    - If a URL cannot be accessed or lacks a publish time, note that in limitations.
    - Use only the sources you retrieved in this run.
    - If the user request involves predictions, ratios, or valuation metrics,
      extract formulas and variable definitions into metrics_formulas for
      internal use; do not surface formulas in the final response unless
      the user requests them or they are directly explanatory.
  expected_output: >
    Return strict JSON with these keys:
    - drivers: list of 2 to 4 objects with fields:
      - driver: short title
      - why_it_matters: 1 to 3 sentences
      - citations: list of objects with fields url, published_at, evidence
    - articles: list of objects with fields:
      - url
      - headline
      - published_at
      - key_points (list of strings)
    - metrics_formulas: list of objects with fields:
      - metric
      - formula
      - variables
      - citation_url
    - limitations: list of strings (empty if none)

quant_snapshot_task:
  description: >
    You are given a quantitative request:
    Symbol: {symbol}
    Interval: {interval}
    Output size: {outputsize}
    Horizon days: {horizon_days}
    Request: {request}
    Provided data (optional): {provided_data}

    Decide which computations are needed based on the Request. Do not compute
    everything by default.

    If provided_data is supplied, use it and do not call market_data_fetch unless
    the Request explicitly asks for fresh market data.
    If provided_data is not supplied and market data is needed, use market_data_fetch.

    Use safe_python_exec as a calculator. Prefer small, single-purpose scripts.
    Each call should accept simplified input data, compute one logical step,
    and print a single JSON object to stdout. Allowed modules: math, statistics,
    datetime, time, json, numpy, pandas.

    If safe_python_exec returns CODE_ERROR, fix the code and retry. Do not proceed
    until you get SUCCESS or you have retried 3 times, then return the error in
    limitations.

    Coding rules (important to avoid exec errors):
    - No leading indentation at top-level lines.
    - Use 4 spaces for indents inside blocks only.
    - Do not include code fences or markdown in the code string.
    - Prefer single-line expressions over multi-line blocks where possible.
    - When parsing dates, use pandas to_datetime with errors="coerce" and format="mixed".
    - Normalize input data before building the DataFrame:
      - If data is a JSON string, parse it with json.loads.
      - If data is a dict with a "data" key, use data["data"] as records.
      - If data is a list, use it directly as records.
      - If records are strings, parse each element with json.loads.
      - If required columns are missing, return a limitation explaining it.
    - Do not call exit(); return a limitations list instead.

    Default fallback (when Request is empty or unclear):
    - last_close, returns_1d, volatility_annualized, data_points.

    Scenarios (only if relevant to the Request):
    - base: expected return over horizon_days
    - bull: expected return + 1.0 * volatility over horizon_days
    - bear: expected return - 1.0 * volatility over horizon_days

    Use the last_close as the starting price if scenarios are computed. Explain
    assumptions in the output.

    Output must include as_of, snapshot, and limitations. Include scenarios only
    if you computed them.

    Use only the available data; if data is missing, state limitations.
  expected_output: >
    Return strict JSON with these keys:
    - as_of: object with timestamp and provider
    - snapshot: object with data_points and computed metrics (keys vary by Request)
    - scenarios: optional object with base, bull, bear each containing price_target,
      range_low, range_high, and assumptions
    - limitations: list of strings (empty if none)

planner_task:
  description: >
    You are the Planner and Report Synthesizer. Inputs:
    User request: {user_request}
    Conversation summary (optional): {conversation_summary}
    Runtime defaults (optional): {runtime_defaults}
    Research output (optional): {research_output}
    Quant output (optional): {quant_output}
    Audit output (optional): {audit_output}
    Sources requested by user (optional): {sources_requested}

    Decide which modules are needed based on the request. Keep the plan minimal.
    If audit_output is REJECTED, specify only the failed parts to rerun.
    If required outputs are already present and approved, produce the final response.
    If you use research_output or quant_output, set use_audit to true.
    For predictive requests, plan to use Research to gather relevant ratios,
    formulas, and contextual drivers, and use Quant to fetch market data and
    compute those ratios via the Python calculator. Use longer time horizons
    where reasonable and frame outputs as scenario-based, not guaranteed.
    If research_output contains metrics_formulas, pass them into quant_request
    as part of the request or provided_data so the Quant agent can compute them.
    If multiple symbols are requested, generate a plan that runs quant per symbol
    (one per request), or pick a single symbol and note the limitation.

    Final response rules:
    - Do not include citations by default.
    - If sources are requested, include them.
    - Do not invent facts or numbers.
    - Only mention failed items in limitations; do not restate corrected failures.
    - Do not output JSON in final_response; write human-readable text only.
    - Only use numbers that appear in quant_output.
    - If research_output is missing, avoid news claims and state limitations.
    - Do not include formulas/variable definitions unless the user requests
      them or they are directly explanatory for the prediction.

    Formatting (human readable, concise):
    - Use short section headers.
    - Prefer bullets over long paragraphs.
    - Recommended sections (include only what is available):
      - Summary
      - Snapshot (numbers)
      - Scenarios (if computed)
      - Stance (watch/monitor/avoid) + risks
      - Limitations
  expected_output: >
    Return strict JSON with these keys:
    - plan: object with use_research, use_quant, use_audit, rationale
    - research_request: optional object with query, tickers, sites, days, max_articles
    - quant_request: optional object with request, symbol, provided_data
    - final_response: optional string
    - notes: list of strings

audit_task:
  description: >
    You are the Auditor. Inputs:
    User request: {user_request}
    Research output (optional): {research_output}
    Quant output (optional): {quant_output}
    Draft response (optional): {draft_response}

    Validate:
    - Numeric sanity (ranges, signs, missing fields).
    - Evidence exists in research_output for factual claims.
    - Narrative is consistent with numbers.
    - Output is complete for the request.
    - Compliance: no personalized advice or guaranteed returns.
    - If the request is predictive, ensure assumptions are provided and that
      any formulas needed exist in research_output (metrics_formulas) or are
      otherwise documented for internal use. Only surface formulas to the user
      when requested or directly explanatory.

    If anything fails, return REJECTED with precise fix actions.
  expected_output: >
    Return strict JSON with these keys:
    - audit_status: APPROVED | REJECTED | PARTIAL
    - issues: list of objects with category, problem, fix_action
    - approved_modules: list of strings
    - required_reruns: list of strings (values: research, quant, planner)
    - notes: list of strings
